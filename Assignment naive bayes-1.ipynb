{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "779fbdef-ff61-4d6e-9b40-28239d7cf090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n**Q1. What is Bayes' Theorem?**\\n\\nBayes' Theorem is a fundamental concept in probability theory that describes how to update the probabilities of hypotheses when given evidence. It allows you to calculate the probability of a hypothesis based on prior knowledge and new evidence.\\n\\n**Q2. What is the formula for Bayes' Theorem?**\\n\\nThe formula for Bayes' Theorem is as follows:\\n\\\\[\\nP(A|B) = \\x0crac{P(B|A) \\\\cdot P(A)}{P(B)}\\n\\\\]\\nwhere:\\n- \\\\(P(A|B)\\\\) is the posterior probability of event \\\\(A\\\\) given event \\\\(B\\\\).\\n- \\\\(P(B|A)\\\\) is the likelihood of event \\\\(B\\\\) given event \\\\(A\\\\).\\n- \\\\(P(A)\\\\) is the prior probability of event \\\\(A\\\\).\\n- \\\\(P(B)\\\\) is the marginal probability of event \\\\(B\\\\).\\n\\n**Q3. How is Bayes' Theorem used in practice?**\\n\\nBayes' Theorem is used in various fields, such as:\\n- **Medical Diagnosis:** To calculate the probability of a disease given a positive test result.\\n- **Spam Filtering:** To determine the probability that an email is spam based on its content.\\n- **Machine Learning:** In algorithms like Naive Bayes classifiers, to update the probability of a hypothesis based on new data.\\n- **Risk Assessment:** To evaluate the likelihood of certain events occurring in finance and insurance.\\n\\n**Q4. What is the relationship between Bayes' Theorem and conditional probability?**\\n\\nBayes' Theorem is directly related to conditional probability. It provides a way to calculate the conditional probability of one event given another event using the reverse conditional probabilities. Essentially, Bayes' Theorem allows you to update the probability of an event based on new evidence, which is the essence of conditional probability.\\n\\n**Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?**\\n\\nThe choice of Naive Bayes classifier depends on the nature of the data:\\n- **Gaussian Naive Bayes:** Used when the features are continuous and normally distributed.\\n- **Multinomial Naive Bayes:** Suitable for discrete data, like word counts in text classification.\\n- **Bernoulli Naive Bayes:** Used when features are binary (e.g., presence or absence of a word in text classification).\\n\\n**Q6. Assignment:**\\n\\nLet's use Naive Bayes to classify a new instance with features \\\\(X1 = 3\\\\) and \\\\(X2 = 4\\\\). The table shows the frequency of each feature value for each class. Assuming equal prior probabilities for each class, we'll calculate the probabilities and determine the predicted class.\\n\\n**Step-by-Step Solution:**\\n\\n1. **Calculate the Likelihoods:**\\n   \\\\[\\n   P(X1=3|A) = \\x0crac{4}{3+3+4} = \\x0crac{4}{10} = 0.4\\n   \\\\]\\n   \\\\[\\n   P(X2=4|A) = \\x0crac{3}{4+3+3+3} = \\x0crac{3}{13} \\x07pprox 0.2308\\n   \\\\]\\n   \\\\[\\n   P(X1=3|B) = \\x0crac{1}{2+2+1} = \\x0crac{1}{5} = 0.2\\n   \\\\]\\n   \\\\[\\n   P(X2=4|B) = \\x0crac{3}{2+2+2+3} = \\x0crac{3}{9} \\x07pprox 0.3333\\n   \\\\]\\n\\n2. **Calculate the Prior Probabilities (Assumed equal):**\\n   \\\\[\\n   P(A) = P(B) = 0.5\\n   \\\\]\\n\\n3. **Calculate the Posterior Probabilities:**\\n   \\\\[\\n   P(A|X1=3, X2=4) \\\\propto P(X1=3|A) \\\\cdot P(X2=4|A) \\\\cdot P(A)\\n   \\\\]\\n   \\\\[\\n   P(A|X1=3, X2=4) \\\\propto 0.4 \\\\cdot 0.2308 \\\\cdot 0.5 \\x07pprox 0.04615\\n   \\\\]\\n   \\\\[\\n   P(B|X1=3, X2=4) \\\\propto P(X1=3|B) \\\\cdot P(X2=4|B) \\\\cdot P(B)\\n   \\\\]\\n   \\\\[\\n   P(B|X1=3, X2=4) \\\\propto 0.2 \\\\cdot 0.3333 \\\\cdot 0.5 \\x07pprox 0.03333\\n   \\\\]\\n\\n4. **Determine the Predicted Class:**\\n   Since \\\\(P(A|X1=3, X2=4) > P(B|X1=3, X2=4)\\\\), the predicted class is \\\\(A\\\\).\\n\\nNaive Bayes would predict the new instance with features \\\\(X1 = 3\\\\) and \\\\(X2 = 4\\\\) to belong to class \\\\(A\\\\).\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "**Q1. What is Bayes' Theorem?**\n",
    "\n",
    "Bayes' Theorem is a fundamental concept in probability theory that describes how to update the probabilities of hypotheses when given evidence. It allows you to calculate the probability of a hypothesis based on prior knowledge and new evidence.\n",
    "\n",
    "**Q2. What is the formula for Bayes' Theorem?**\n",
    "\n",
    "The formula for Bayes' Theorem is as follows:\n",
    "\\[\n",
    "P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n",
    "\\]\n",
    "where:\n",
    "- \\(P(A|B)\\) is the posterior probability of event \\(A\\) given event \\(B\\).\n",
    "- \\(P(B|A)\\) is the likelihood of event \\(B\\) given event \\(A\\).\n",
    "- \\(P(A)\\) is the prior probability of event \\(A\\).\n",
    "- \\(P(B)\\) is the marginal probability of event \\(B\\).\n",
    "\n",
    "**Q3. How is Bayes' Theorem used in practice?**\n",
    "\n",
    "Bayes' Theorem is used in various fields, such as:\n",
    "- **Medical Diagnosis:** To calculate the probability of a disease given a positive test result.\n",
    "- **Spam Filtering:** To determine the probability that an email is spam based on its content.\n",
    "- **Machine Learning:** In algorithms like Naive Bayes classifiers, to update the probability of a hypothesis based on new data.\n",
    "- **Risk Assessment:** To evaluate the likelihood of certain events occurring in finance and insurance.\n",
    "\n",
    "**Q4. What is the relationship between Bayes' Theorem and conditional probability?**\n",
    "\n",
    "Bayes' Theorem is directly related to conditional probability. It provides a way to calculate the conditional probability of one event given another event using the reverse conditional probabilities. Essentially, Bayes' Theorem allows you to update the probability of an event based on new evidence, which is the essence of conditional probability.\n",
    "\n",
    "**Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?**\n",
    "\n",
    "The choice of Naive Bayes classifier depends on the nature of the data:\n",
    "- **Gaussian Naive Bayes:** Used when the features are continuous and normally distributed.\n",
    "- **Multinomial Naive Bayes:** Suitable for discrete data, like word counts in text classification.\n",
    "- **Bernoulli Naive Bayes:** Used when features are binary (e.g., presence or absence of a word in text classification).\n",
    "\n",
    "**Q6. Assignment:**\n",
    "\n",
    "Let's use Naive Bayes to classify a new instance with features \\(X1 = 3\\) and \\(X2 = 4\\). The table shows the frequency of each feature value for each class. Assuming equal prior probabilities for each class, we'll calculate the probabilities and determine the predicted class.\n",
    "\n",
    "**Step-by-Step Solution:**\n",
    "\n",
    "1. **Calculate the Likelihoods:**\n",
    "   \\[\n",
    "   P(X1=3|A) = \\frac{4}{3+3+4} = \\frac{4}{10} = 0.4\n",
    "   \\]\n",
    "   \\[\n",
    "   P(X2=4|A) = \\frac{3}{4+3+3+3} = \\frac{3}{13} \\approx 0.2308\n",
    "   \\]\n",
    "   \\[\n",
    "   P(X1=3|B) = \\frac{1}{2+2+1} = \\frac{1}{5} = 0.2\n",
    "   \\]\n",
    "   \\[\n",
    "   P(X2=4|B) = \\frac{3}{2+2+2+3} = \\frac{3}{9} \\approx 0.3333\n",
    "   \\]\n",
    "\n",
    "2. **Calculate the Prior Probabilities (Assumed equal):**\n",
    "   \\[\n",
    "   P(A) = P(B) = 0.5\n",
    "   \\]\n",
    "\n",
    "3. **Calculate the Posterior Probabilities:**\n",
    "   \\[\n",
    "   P(A|X1=3, X2=4) \\propto P(X1=3|A) \\cdot P(X2=4|A) \\cdot P(A)\n",
    "   \\]\n",
    "   \\[\n",
    "   P(A|X1=3, X2=4) \\propto 0.4 \\cdot 0.2308 \\cdot 0.5 \\approx 0.04615\n",
    "   \\]\n",
    "   \\[\n",
    "   P(B|X1=3, X2=4) \\propto P(X1=3|B) \\cdot P(X2=4|B) \\cdot P(B)\n",
    "   \\]\n",
    "   \\[\n",
    "   P(B|X1=3, X2=4) \\propto 0.2 \\cdot 0.3333 \\cdot 0.5 \\approx 0.03333\n",
    "   \\]\n",
    "\n",
    "4. **Determine the Predicted Class:**\n",
    "   Since \\(P(A|X1=3, X2=4) > P(B|X1=3, X2=4)\\), the predicted class is \\(A\\).\n",
    "\n",
    "Naive Bayes would predict the new instance with features \\(X1 = 3\\) and \\(X2 = 4\\) to belong to class \\(A\\).\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f3730d-a1cf-4da5-93fd-c54652ee1ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
